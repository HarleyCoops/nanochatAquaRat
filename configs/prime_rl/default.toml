# Prime Intellect RL Configuration for NanochatAquaRat
# Default configuration for training with Prime RL framework

# Model configuration
model = "nanochat-sft"  # Path to checkpoint or model name

[env]
# Prime Intellect environment from the Environments Hub
id = "harleycooper/nanochatAquaRat"

[env.args]
# Environment-specific arguments
num_train_examples = 2000  # Number of training examples (-1 for all)
num_eval_examples = 254    # Number of evaluation examples
seed = 42
include_rationale_metadata = true
system_prompt = "You are an algebra tutor. Solve each problem, show your reasoning, and end with 'Answer: <letter>' where <letter> is one of A, B, C, D, or E."

[trainer]
# Trainer configuration

[trainer.args]
# Training hyperparameters
learning_rate = 2e-5
rollouts_per_example = 8   # Number of samples per training example
max_steps = 400            # Maximum training steps
per_device_train_batch_size = 4
gradient_accumulation_steps = 4
eval_steps = 50
save_steps = 100
logging_steps = 10

# RL-specific parameters
temperature = 1.0
top_k = 50
max_new_tokens = 256

# Optimization
weight_decay = 0.0
warmup_steps = 50
max_grad_norm = 1.0

# W&B integration
report_to = ["wandb"]
run_name = "prime_rl_default"

[wandb]
project = "nanochat-prime-rl"
tags = ["prime-rl", "nanochat", "aquarat", "default"]
notes = "Default Prime Intellect RL training configuration"
